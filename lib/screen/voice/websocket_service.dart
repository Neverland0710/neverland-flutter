import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';

import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:web_socket_channel/io.dart';
import 'package:web_socket_channel/web_socket_channel.dart';

class WebSocketService {
  WebSocketChannel? _channel;
  final List<Uint8List> _audioBuffer = [];
  Timer? _bufferTimer;
  Timer? _pingTimer;

  // MP3 í”Œë ˆì´ì–´
  final FlutterSoundPlayer _player = FlutterSoundPlayer();

  // ì½œë°±
  Function(String)? onTextResponse;
  Function()? onAudioStart;
  Function()? onAudioEnd;
  Function(String)? onError;
  Function()? onConnectionLost;
  Function()? onReconnected; // âœ… ì¶”ê°€ëœ ì½œë°±

  String get _backendUrl => dotenv.env['BACKEND_URL'] ?? 'ws://localhost:8080/ws/audio';
  bool get isConnected => _channel != null;

  WebSocketService() {
    _initPlayer(); // í”Œë ˆì´ì–´ ì´ˆê¸°í™”
  }

  Future<void> _initPlayer() async {
    await _player.openPlayer();
  }

  Future<void> _disposePlayer() async {
    await _player.stopPlayer();
    await _player.closePlayer();
  }

  Future<void> connect() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final authKeyId = prefs.getString('auth_key_id') ?? '';
      final wsUrl = _backendUrl;

      _channel = IOWebSocketChannel.connect(Uri.parse(wsUrl));
      _channel!.sink.add(jsonEncode({
        'type': 'auth',
        'authKeyId': authKeyId,
        'timestamp': DateTime.now().toIso8601String(),
      }));

      _channel!.stream.listen(
            (data) {
          if (data is String) {
            _handleMessage(data);
          } else if (data is Uint8List) {
            _enqueueAudio(data);
          }
        },
        onError: (error) {
          onError?.call('WebSocket ì—°ê²° ì˜¤ë¥˜');
          _scheduleReconnect();
        },
        onDone: () {
          onConnectionLost?.call();
          _scheduleReconnect();
        },
      );

      // ì•½ê°„ì˜ ë”œë ˆì´ í›„ connect ë©”ì‹œì§€ ì „ì†¡
      await Future.delayed(const Duration(milliseconds: 500));
      await sendMessage({
        'type': 'connect',
        'timestamp': DateTime.now().toIso8601String(),
      });

      _startPingTimer();

      // âœ… ì—°ê²° ì„±ê³µ ì•Œë¦¼
      onReconnected?.call();
    } catch (e) {
      onError?.call('ì„œë²„ ì—°ê²° ì‹¤íŒ¨');
      _scheduleReconnect();
    }
  }

  Future<void> sendMessage(Map<String, dynamic> message) async {
    _channel?.sink.add(json.encode(message));
  }

  Future<void> sendUserMessage(String text) async {
    await sendMessage({
      'type': 'user_message',
      'text': text,
      'timestamp': DateTime.now().toIso8601String(),
    });
  }

  Future<void> sendDisconnect() async {
    await sendMessage({
      'type': 'disconnect',
      'timestamp': DateTime.now().toIso8601String(),
    });
  }

  void _handleMessage(dynamic data) async {
    try {
      if (data is String) {
        // JSONìœ¼ë¡œ íŒŒì‹± ê°€ëŠ¥í•œì§€ í™•ì¸
        try {
          final message = json.decode(data);

          switch (message['type']) {
            case 'audio_chunk':
              final audioBytes = base64Decode(message['audio_data']);
              _enqueueAudio(audioBytes);
              break;
            case 'audio_start':
              onAudioStart?.call();
              break;
            case 'audio_end':
              onAudioEnd?.call();
              break;
            case 'text_response':
              final text = message['text']?.toString() ?? '';
              onTextResponse?.call(text);
              break;
            case 'error':
              onError?.call(message['message'] ?? 'ì„œë²„ ì˜¤ë¥˜');
              break;
            case 'pong':
              break;
            default:
              onError?.call('ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: ${message['type']}');
          }
        } catch (e) {
          // âœ… JSONì´ ì•„ë‹ˆë¼ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
          print('ğŸ“¨ ì¼ë°˜ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ : $data');
          onTextResponse?.call(data); // ë°”ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤Œ
        }
      } else if (data is Uint8List) {
        _enqueueAudio(data);
      } else {
        onError?.call('ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° í˜•ì‹: ${data.runtimeType}');
      }
    } catch (e) {
      onError?.call('ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: $e');
      print('ğŸ“› ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨. ì›ë³¸ ë°ì´í„°: $data');
    }
  }



  void _enqueueAudio(Uint8List chunk) {
    _audioBuffer.add(chunk);
    _bufferTimer?.cancel();
    _bufferTimer = Timer(const Duration(milliseconds: 500), () {
      _playBufferedMp3();
    });
  }

  Future<void> _playBufferedMp3() async {
    if (_audioBuffer.isEmpty) return;
    final combined = _audioBuffer.expand((e) => e).toList();
    _audioBuffer.clear();

    try {
      final dir = await getTemporaryDirectory();
      final path = '${dir.path}/buffered_audio.mp3';
      final file = File(path);
      await file.writeAsBytes(combined, flush: true);

      await _player.startPlayer(
        fromURI: path,
        codec: Codec.mp3,
        whenFinished: () => onAudioEnd?.call(),
      );
    } catch (e) {
      onError?.call('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨: $e');
    }
  }

  void _startPingTimer() {
    _pingTimer?.cancel();
    _pingTimer = Timer.periodic(const Duration(seconds: 30), (_) {
      sendMessage({
        'type': 'ping',
        'timestamp': DateTime.now().toIso8601String(),
      });
    });
  }

  void _scheduleReconnect() {
    Future.delayed(const Duration(seconds: 5), () {
      connect();
    });
  }

  Future<void> dispose() async {
    _pingTimer?.cancel();
    _bufferTimer?.cancel();
    _audioBuffer.clear();
    await _disposePlayer();
    await _channel?.sink.close();
    _channel = null;
  }
}
